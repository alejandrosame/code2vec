{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 repositories successfully loaded\n"
     ]
    }
   ],
   "source": [
    "from sourced.engine import Engine\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    ".master(\"local[*]\").appName(\"Examples\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "engine = Engine(spark, \"/repositories/test\", \"siva\")\n",
    "\n",
    "print(\"%d repositories successfully loaded\" % (engine.repositories.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repositories schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = false)\n",
      " |-- urls: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- is_fork: boolean (nullable = true)\n",
      " |-- repository_path: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repository_id: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- is_remote: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.references.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commits schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repository_id: string (nullable = false)\n",
      " |-- reference_name: string (nullable = false)\n",
      " |-- index: integer (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- message: string (nullable = false)\n",
      " |-- parents: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- parents_count: integer (nullable = false)\n",
      " |-- author_email: string (nullable = true)\n",
      " |-- author_name: string (nullable = true)\n",
      " |-- author_date: timestamp (nullable = true)\n",
      " |-- committer_email: string (nullable = true)\n",
      " |-- committer_name: string (nullable = true)\n",
      " |-- committer_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.references.commits.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- blob_id: string (nullable = false)\n",
      " |-- commit_hash: string (nullable = false)\n",
      " |-- repository_id: string (nullable = false)\n",
      " |-- reference_name: string (nullable = false)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- is_binary: boolean (nullable = false)\n",
      " |-- path: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.references.commits.blobs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Get branch with latest commit for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 repo branches:\n",
      "+--------------------+-----------------+\n",
      "|       repository_id|   reference_name|\n",
      "+--------------------+-----------------+\n",
      "|github.com/AlexPa...|refs/heads/master|\n",
      "|github.com/jmailh...|refs/heads/master|\n",
      "|github.com/geekco...|refs/heads/master|\n",
      "|github.com/dotfen...|refs/heads/master|\n",
      "|github.com/bluepi...|refs/heads/master|\n",
      "|github.com/antoni...|refs/heads/master|\n",
      "|github.com/mingra...|refs/heads/master|\n",
      "+--------------------+-----------------+\n",
      "\n",
      "Repository count after join 7 \n"
     ]
    }
   ],
   "source": [
    "df = engine.repositories.references\\\n",
    "    .filter(\"is_remote = true\")\\\n",
    "    .filter(\"NOT name LIKE 'refs/heads/HEAD' AND name LIKE 'refs/heads/%'\")\\\n",
    "    .commits\\\n",
    "    .cache()\n",
    "    \n",
    "latest_commit = df.groupBy(\"repository_id\").agg(max(\"committer_date\").alias(\"date\"))\\\n",
    "                 .withColumnRenamed('repository_id', 'id')\n",
    "\n",
    "latest_repo_ref = df.select(\"repository_id\", \"reference_name\", \"committer_date\")\\\n",
    "                    .join(latest_commit, \n",
    "                          (df.repository_id == latest_commit.id) \n",
    "                           & (df.committer_date == latest_commit.date))\\\n",
    "                    .select('repository_id', 'reference_name')\\\n",
    "                    .cache()                 \n",
    "\n",
    "print(\"First 10 repo branches:\")\n",
    "latest_repo_ref.show(10)\n",
    "\n",
    "print(\"Repository count after join %d \" % (latest_repo_ref.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting train and test sets\n",
    "\n",
    "We can use randomSplit over the repositories DataFrame to get the train and test sets. The same can be done later to get the train and validation sets depending on the specific cross-validation approach used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count 7 || Train count 4 || Test count 3\n"
     ]
    }
   ],
   "source": [
    "data = latest_repo_ref\\\n",
    "    .withColumnRenamed('repository_id', 'repo_id')\\\n",
    "    .withColumnRenamed('reference_name', 'ref_name')\\\n",
    "\n",
    "[train, test] = data.randomSplit([0.8, 0.2], seed)\n",
    "\n",
    "print(\"Total count %d || Train count %d || Test count %d\" % (data.count(), train.count(), test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train dataset with Python UASTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get Python blobs with UASTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get repo_ids and ref_names to filter and avoid extracting UASTs on all blobs\n",
    "repo_ids, ref_names = set(), set()\n",
    "\n",
    "select = latest_repo_ref.select(\"repository_id\", \"reference_name\").collect()\n",
    "for row in select: repo_ids.add(row.repository_id); ref_names.add(row.reference_name);\n",
    "\n",
    "# Get blobs with UASTs\n",
    "python_blobs = df.blobs\\\n",
    "    .repartition(32)\\\n",
    "    .filter(df.blobs.repository_id.isin(repo_ids))\\\n",
    "    .filter(df.blobs.reference_name.isin(ref_names))\\\n",
    "    .classify_languages()\\\n",
    "    .filter(\"is_binary = false\")\\\n",
    "    .filter(\"lang = 'Python'\")\\\n",
    "    .dropDuplicates(['blob_id'])\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_blobs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_uasts = python_blobs\\\n",
    "    .repartition(32)\\\n",
    "    .extract_uasts()\\\n",
    "    .drop(\"content\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_uasts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join python_blobs dataframe with the train dataframe to get UASTS we want to use for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_python = train\\\n",
    "    .join(python_uasts, \n",
    "       (train.repo_id == python_uasts.repository_id) \n",
    "        & (train.ref_name == python_uasts.reference_name))\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_python.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repo_id: string (nullable = false)\n",
      " |-- ref_name: string (nullable = false)\n",
      " |-- index: integer (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- message: string (nullable = false)\n",
      " |-- parents: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- parents_count: integer (nullable = false)\n",
      " |-- author_email: string (nullable = true)\n",
      " |-- author_name: string (nullable = true)\n",
      " |-- author_date: timestamp (nullable = true)\n",
      " |-- committer_email: string (nullable = true)\n",
      " |-- committer_name: string (nullable = true)\n",
      " |-- committer_date: timestamp (nullable = true)\n",
      " |-- blob_id: string (nullable = true)\n",
      " |-- commit_hash: string (nullable = true)\n",
      " |-- repository_id: string (nullable = true)\n",
      " |-- reference_name: string (nullable = true)\n",
      " |-- is_binary: boolean (nullable = false)\n",
      " |-- path: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- uast: array (nullable = false)\n",
      " |    |-- element: binary (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_python.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
